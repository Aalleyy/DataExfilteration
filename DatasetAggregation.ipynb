{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0ada243b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import timedelta\n",
    "import os\n",
    "\n",
    "# ==========================================\n",
    "# CONFIGURATION & GROUND TRUTH\n",
    "# ==========================================\n",
    "\n",
    "# Timestamps for Data Exfiltration Scenarios (1, 2, 4, 5)\n",
    "# Note: User PLJ1771 (Scenario 3 - IT Sabotage/Keylogger) is EXCLUDED from \n",
    "# the positive class (1) because it is not data exfiltration.\n",
    "MALICIOUS_WINDOWS = {\n",
    "    'ACM2278': ('2010-08-18 21:47:42', '2010-08-24 03:48:51'), # Scn 1: Wikileaks Upload\n",
    "    'CMP2946': ('2011-02-07 12:28:06', '2011-03-04 12:30:25'), # Scn 2: Data Theft (USB)\n",
    "    'CDE1846': ('2011-02-21 11:43:39', '2011-04-25 17:55:00'), # Scn 4: Email to Home\n",
    "    'MBG3183': ('2010-10-12 13:21:59', '2010-10-12 13:22:56'), # Scn 5: Dropbox Upload\n",
    "}\n",
    "\n",
    "# Define the input file names (Adjust paths if your files are in a subfolder)\n",
    "FILES = {\n",
    "    'logon': '../Dataset/r6.2/logon.csv',\n",
    "    'device': '../Dataset/r6.2/device.csv',\n",
    "    'http': '../Dataset/r6.2/http.csv',\n",
    "    'email': '../Dataset/r6.2/email.csv',\n",
    "    'file': '../Dataset/r6.2/file.csv'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7c3b323a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_parse(filepath, date_col='date'):\n",
    "    \"\"\"\n",
    "    Helper function to load CSV and parse dates efficiently.\n",
    "    Handles common encoding issues in CERT datasets.\n",
    "    \"\"\"\n",
    "    print(f\"Loading {filepath}...\")\n",
    "    if not os.path.exists(filepath):\n",
    "        print(f\"[!] Error: File not found {filepath}\")\n",
    "        return pd.DataFrame()\n",
    "        \n",
    "    try:\n",
    "        # r6.2 often uses ISO-8859-1 encoding rather than utf-8\n",
    "        df = pd.read_csv(filepath, encoding='ISO-8859-1') \n",
    "        # Coerce errors to NaT to prevent crashing on bad date formats\n",
    "        df[date_col] = pd.to_datetime(df[date_col], format='%m/%d/%Y %H:%M:%S', errors='coerce')\n",
    "        # Remove rows where date parsing failed\n",
    "        return df.dropna(subset=[date_col]) \n",
    "    except Exception as e:\n",
    "        print(f\"[!] Error loading {filepath}: {e}\")\n",
    "        return pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "516c4a36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ../Dataset/r6.2/logon.csv...\n",
      "Loading ../Dataset/r6.2/device.csv...\n",
      "Loading ../Dataset/r6.2/http.csv...\n",
      "Loading ../Dataset/r6.2/email.csv...\n",
      "Loading ../Dataset/r6.2/file.csv...\n",
      "All datasets loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "# Load all log files\n",
    "logon_df = load_and_parse(FILES['logon'])\n",
    "device_df = load_and_parse(FILES['device'])\n",
    "http_df = load_and_parse(FILES['http'])\n",
    "email_df = load_and_parse(FILES['email'])\n",
    "file_df = load_and_parse(FILES['file'])\n",
    "\n",
    "print(\"All datasets loaded successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fe60a2c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating sessions from logon data...\n",
      "Generated 1881109 unique sessions.\n"
     ]
    }
   ],
   "source": [
    "# Initialize the sessions list\n",
    "sessions = []\n",
    "\n",
    "print(\"Creating sessions from logon data...\")\n",
    "\n",
    "# Sort by User and Date to ensure chronological order\n",
    "logon_df = logon_df.sort_values(by=['user', 'date'])\n",
    "\n",
    "# Group by user to process distinct timelines\n",
    "for user, user_logs in logon_df.groupby('user'):\n",
    "    user_logs = user_logs.reset_index(drop=True)\n",
    "    \n",
    "    i = 0\n",
    "    while i < len(user_logs):\n",
    "        row = user_logs.iloc[i]\n",
    "        \n",
    "        # We start a session when we see a 'Logon'\n",
    "        if row['activity'] == 'Logon':\n",
    "            session_start = row['date']\n",
    "            pc = row['pc']\n",
    "            session_id = row['id']\n",
    "            \n",
    "            # Look ahead for the corresponding Logoff on the SAME PC\n",
    "            session_end = None\n",
    "            j = i + 1\n",
    "            while j < len(user_logs):\n",
    "                next_row = user_logs.iloc[j]\n",
    "                \n",
    "                if next_row['user'] == user and next_row['pc'] == pc:\n",
    "                    if next_row['activity'] == 'Logoff':\n",
    "                        session_end = next_row['date']\n",
    "                        i = j # Advance outer loop to skip this logoff\n",
    "                        break\n",
    "                    elif next_row['activity'] == 'Logon':\n",
    "                        # Found a new logon before a logoff (user didn't log out)\n",
    "                        break\n",
    "                j += 1\n",
    "            \n",
    "            # Handling Missing Logoffs: Cap session at 12 hours max if no logoff found\n",
    "            if session_end is None:\n",
    "                session_end = session_start + timedelta(hours=12)\n",
    "            \n",
    "            sessions.append({\n",
    "                'id': session_id,\n",
    "                'user': user,\n",
    "                'pc': pc,\n",
    "                'session_start': session_start,\n",
    "                'session_end': session_end,\n",
    "                'duration_sec': (session_end - session_start).total_seconds()\n",
    "            })\n",
    "        i += 1\n",
    "\n",
    "sessions_df = pd.DataFrame(sessions)\n",
    "print(f\"Generated {len(sessions_df)} unique sessions.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a444b5eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregating activity logs into sessions (this process takes time)...\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 112. MiB for an array with shape (117025216,) and data type bool",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 11\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m user, user_sessions \u001b[38;5;129;01min\u001b[39;00m sessions_df\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m      8\u001b[0m     \n\u001b[0;32m      9\u001b[0m     \u001b[38;5;66;03m# 1. Pre-filter other dataframes for this user (Optimization)\u001b[39;00m\n\u001b[0;32m     10\u001b[0m     u_email \u001b[38;5;241m=\u001b[39m email_df[email_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m user] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m email_df\u001b[38;5;241m.\u001b[39mempty \u001b[38;5;28;01melse\u001b[39;00m pd\u001b[38;5;241m.\u001b[39mDataFrame()\n\u001b[1;32m---> 11\u001b[0m     u_http \u001b[38;5;241m=\u001b[39m http_df[\u001b[43mhttp_df\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m http_df\u001b[38;5;241m.\u001b[39mempty \u001b[38;5;28;01melse\u001b[39;00m pd\u001b[38;5;241m.\u001b[39mDataFrame()\n\u001b[0;32m     12\u001b[0m     u_device \u001b[38;5;241m=\u001b[39m device_df[device_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m user] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m device_df\u001b[38;5;241m.\u001b[39mempty \u001b[38;5;28;01melse\u001b[39;00m pd\u001b[38;5;241m.\u001b[39mDataFrame()\n\u001b[0;32m     13\u001b[0m     u_file \u001b[38;5;241m=\u001b[39m file_df[file_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m user] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m file_df\u001b[38;5;241m.\u001b[39mempty \u001b[38;5;28;01melse\u001b[39;00m pd\u001b[38;5;241m.\u001b[39mDataFrame()\n",
      "File \u001b[1;32mc:\\Users\\Ali\\miniconda3\\envs\\gpu-main\\lib\\site-packages\\pandas\\core\\ops\\common.py:76\u001b[0m, in \u001b[0;36m_unpack_zerodim_and_defer.<locals>.new_method\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m     72\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[0;32m     74\u001b[0m other \u001b[38;5;241m=\u001b[39m item_from_zerodim(other)\n\u001b[1;32m---> 76\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Ali\\miniconda3\\envs\\gpu-main\\lib\\site-packages\\pandas\\core\\arraylike.py:40\u001b[0m, in \u001b[0;36mOpsMixin.__eq__\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;129m@unpack_zerodim_and_defer\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__eq__\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__eq__\u001b[39m(\u001b[38;5;28mself\u001b[39m, other):\n\u001b[1;32m---> 40\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cmp_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meq\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Ali\\miniconda3\\envs\\gpu-main\\lib\\site-packages\\pandas\\core\\series.py:6138\u001b[0m, in \u001b[0;36mSeries._cmp_method\u001b[1;34m(self, other, op)\u001b[0m\n\u001b[0;32m   6135\u001b[0m lvalues \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values\n\u001b[0;32m   6136\u001b[0m rvalues \u001b[38;5;241m=\u001b[39m extract_array(other, extract_numpy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, extract_range\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m-> 6138\u001b[0m res_values \u001b[38;5;241m=\u001b[39m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcomparison_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   6140\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_construct_result(res_values, name\u001b[38;5;241m=\u001b[39mres_name)\n",
      "File \u001b[1;32mc:\\Users\\Ali\\miniconda3\\envs\\gpu-main\\lib\\site-packages\\pandas\\core\\ops\\array_ops.py:344\u001b[0m, in \u001b[0;36mcomparison_op\u001b[1;34m(left, right, op)\u001b[0m\n\u001b[0;32m    341\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m invalid_comparison(lvalues, rvalues, op)\n\u001b[0;32m    343\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m lvalues\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(rvalues, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m--> 344\u001b[0m     res_values \u001b[38;5;241m=\u001b[39m \u001b[43mcomp_method_OBJECT_ARRAY\u001b[49m\u001b[43m(\u001b[49m\u001b[43mop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrvalues\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    346\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    347\u001b[0m     res_values \u001b[38;5;241m=\u001b[39m _na_arithmetic_op(lvalues, rvalues, op, is_cmp\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\Ali\\miniconda3\\envs\\gpu-main\\lib\\site-packages\\pandas\\core\\ops\\array_ops.py:129\u001b[0m, in \u001b[0;36mcomp_method_OBJECT_ARRAY\u001b[1;34m(op, x, y)\u001b[0m\n\u001b[0;32m    127\u001b[0m     result \u001b[38;5;241m=\u001b[39m libops\u001b[38;5;241m.\u001b[39mvec_compare(x\u001b[38;5;241m.\u001b[39mravel(), y\u001b[38;5;241m.\u001b[39mravel(), op)\n\u001b[0;32m    128\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 129\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mlibops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscalar_compare\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mravel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    130\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\u001b[38;5;241m.\u001b[39mreshape(x\u001b[38;5;241m.\u001b[39mshape)\n",
      "File \u001b[1;32mpandas/_libs/ops.pyx:71\u001b[0m, in \u001b[0;36mpandas._libs.ops.scalar_compare\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 112. MiB for an array with shape (117025216,) and data type bool"
     ]
    }
   ],
   "source": [
    "# Initialize list to store final dataset rows\n",
    "final_rows = []\n",
    "\n",
    "print(\"Aggregating activity logs into sessions (this process takes time)...\")\n",
    "\n",
    "# Process per user to speed up filtering\n",
    "for user, user_sessions in sessions_df.groupby('user'):\n",
    "    \n",
    "    # 1. Pre-filter other dataframes for this user (Optimization)\n",
    "    u_email = email_df[email_df['user'] == user] if not email_df.empty else pd.DataFrame()\n",
    "    u_http = http_df[http_df['user'] == user] if not http_df.empty else pd.DataFrame()\n",
    "    u_device = device_df[device_df['user'] == user] if not device_df.empty else pd.DataFrame()\n",
    "    u_file = file_df[file_df['user'] == user] if not file_df.empty else pd.DataFrame()\n",
    "\n",
    "    for _, session in user_sessions.iterrows():\n",
    "        start = session['session_start']\n",
    "        end = session['session_end']\n",
    "        \n",
    "        # --- EMAIL FEATURES ---\n",
    "        # Get emails sent during this session\n",
    "        sess_emails = u_email[(u_email['date'] >= start) & (u_email['date'] <= end)]\n",
    "        email_count = len(sess_emails)\n",
    "        \n",
    "        # Concatenate email content for the Autoencoder text field\n",
    "        email_text_list = []\n",
    "        for _, r in sess_emails.iterrows():\n",
    "            to_val = str(r['to']) if pd.notna(r.get('to')) else \"\"\n",
    "            content_val = str(r['content']) if pd.notna(r.get('content')) else \"\"\n",
    "            email_text_list.append(f\"TO: {to_val} BODY: {content_val}\")\n",
    "        \n",
    "        email_content = \" | \".join(email_text_list)\n",
    "\n",
    "        # --- HTTP FEATURES ---\n",
    "        sess_http = u_http[(u_http['date'] >= start) & (u_http['date'] <= end)]\n",
    "        http_count = len(sess_http)\n",
    "        \n",
    "        http_text_list = []\n",
    "        for _, r in sess_http.iterrows():\n",
    "            url_val = str(r['url']) if pd.notna(r.get('url')) else \"\"\n",
    "            content_val = str(r['content']) if pd.notna(r.get('content')) else \"\"\n",
    "            http_text_list.append(f\"{url_val} {content_val}\")\n",
    "        \n",
    "        http_content = \" | \".join(http_text_list)\n",
    "        \n",
    "        # --- DEVICE/FILE FEATURES ---\n",
    "        sess_device = u_device[(u_device['date'] >= start) & (u_device['date'] <= end)]\n",
    "        sess_files = u_file[(u_file['date'] >= start) & (u_file['date'] <= end)]\n",
    "        \n",
    "        device_count = len(sess_device)\n",
    "        file_count = len(sess_files)\n",
    "        \n",
    "        # Calculate file copies to USB (Key indicator for Exfiltration)\n",
    "        files_copied_to_usb = 0\n",
    "        if 'to_removable_media' in sess_files.columns:\n",
    "             files_copied_to_usb = len(sess_files[sess_files['to_removable_media'] == True])\n",
    "        elif 'filename' in sess_files.columns:\n",
    "            # Fallback: check if file path starts with removable drive letter (often R:)\n",
    "            files_copied_to_usb = len(sess_files[sess_files['filename'].str.startswith('R:', na=False)])\n",
    "\n",
    "        # --- LABELING LOGIC (FIXED) ---\n",
    "        label = 0\n",
    "        if user in MALICIOUS_WINDOWS:\n",
    "            # FIX: Explicitly select index 0 for start and 1 for end\n",
    "            mal_start = pd.to_datetime(MALICIOUS_WINDOWS[user][0])\n",
    "            mal_end = pd.to_datetime(MALICIOUS_WINDOWS[user][1])\n",
    "            \n",
    "            # Check for time overlap\n",
    "            if (start <= mal_end) and (end >= mal_start):\n",
    "                label = 1\n",
    "\n",
    "        # --- ROW CONSTRUCTION ---\n",
    "        final_rows.append({\n",
    "            'id': session['id'],\n",
    "            'user': user,\n",
    "            'session_start': start,\n",
    "            'session_end': end,\n",
    "            'duration': session['duration_sec'],\n",
    "            'logon_activity': 1, \n",
    "            'email_activity': email_count,\n",
    "            'email_content': email_content, \n",
    "            'http_activity': http_count,\n",
    "            'http_content': http_content,\n",
    "            'device_activity': device_count,\n",
    "            'file_activity': file_count,\n",
    "            'files_copied_to_usb': files_copied_to_usb,\n",
    "            'label': label\n",
    "        })\n",
    "\n",
    "print(\"Aggregation complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f424a2f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to DataFrame\n",
    "df_final = pd.DataFrame(final_rows)\n",
    "\n",
    "# Save\n",
    "output_filename = \"../CombinedDataset/cert_r6.2_session_dataset.csv\"\n",
    "df_final.to_csv(output_filename, index=False)\n",
    "\n",
    "print(f\"Dataset created: {output_filename}\")\n",
    "print(f\"Total Sessions: {len(df_final)}\")\n",
    "print(f\"Anomalous (Exfiltration) Sessions: {df_final['label'].sum()}\")\n",
    "\n",
    "# Show a preview\n",
    "df_final.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu-main",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
